//
#function that generates embeddings from text 
def get_embedding(text, model='text-embedding-ada-002'):
    text = text.replace("\n", " ")
    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']

df = pd.read_csv('/Users/emilyhalperin/Desktop/halpreads.csv')
conn = sqlite3.connect('instance/app.db')
df.to_sql('halpreads', conn, if_exists='append', index=False)

# Generate embeddings for each text in dataset
df['Summary'] = df.Summary.apply(eval).apply(lambda x: "{}".join(x))
#applies the get_embedding() function to each element in the elmbedding column of the datafram
#x.tolist() convert the NumPy array x to a python list (since function expects a list of str as input)
#resulting embedding is returned and assigned to the embedding column of the dataframe
df['embedding'] = df.Summary.apply(lambda x: get_embedding(x.tolist()))

# Define function to get recommendations based on embeddings
def recommendations_from_strings(strings: List[str], index_of_source_string: int, model="text-embedding-ada-002") -> List[int]:
    """Return nearest neighbors of a given string."""

    # get embeddings for all strings
    embeddings = [get_embedding(string, model=model) for string in strings]

    # get the embedding of the source string
    query_embedding = embeddings[index_of_source_string]

    # calculate cosine similarity between source embedding and other embeddings
    similarities = np.dot(embeddings, query_embedding) / (np.linalg.norm(embeddings, axis=1) * np.linalg.norm(query_embedding))

    # get indices of nearest neighbors
    indices_of_nearest_neighbors = np.argsort(-similarities).tolist()
    return indices_of_nearest_neighbors

@chat_gpt_route.route('/search')
def search():
    query = request.args.get('query')
    query_embedding = get_embedding(query)
    best_match = None
    best_match_similarity = 0
    for book in dfList:
        book_embedding = np.array(book['embedding'])
        similarity = cosine_similarity([query_embedding], [book_embedding])[0][0]
        if similarity > best_match_similarity:
            best_match = book
            best_match_similarity = similarity
    # `best_match` now contains the book summary with the most similar embedding to the user query

    response = {
        'title': best_match['Title'],
        'genre': best_match['Genre'],
        'rating': best_match['Rating'],
        'summary': best_match['Summary']
    }

    return jsonify(response)










# function that generates embeddings from text 
def get_embedding(text, model='text-embedding-ada-002'):
    if isinstance(text, str):
        text = text.replace("\n", " ")
        return openai.Embedding.create(input=[text], model=model)['data'][0]['embedding']
    else:
        return None

df = pd.read_csv('/Users/emilyhalperin/Desktop/halpreads.csv')
conn = sqlite3.connect('instance/app.db')
df.to_sql('halpreads', conn, if_exists='append', index=False)
df['Summary_Embedding'] = df.Summary.replace("\n", " ").apply(get_embedding)


dfList = []
for index, row in df.iterrows():
    #print(index) #To keep track of which row we are on

    # Create an empty dictionary to store the information for this row
    entry = {}
    entry['Title'] = row['Title']
    entry['Author'] = row['Author']
    entry['Genre'] = row['Genre']
    entry['Rating']= row['Rating']
    entry['Summary'] = row['Summary']
    entry['embedding'] = row['Summary_Embedding']

    # If the 'summary' column is a string and its length is greater than or equal to 33000...
    if isinstance(row['Summary'], str) and len(row['Summary']) >= 33000:
        # ... split the 'summary' value at the first period (.) after the middle of the string and take the second half as the first substring
        embedding1 = openai.Embedding.create(
            input = row['Summary'][row['Summary'].find('.', int (len(row['Summary'])/2))+1:], model="text-embedding-ada-002")['data'][0]['embedding']
        # ... take the first half of the 'summary' value as the second substring
        embedding2 = openai.Embedding.create(
            input = row['Summary'][:row['Summary'].find('.', int (len(row['Summary'])/2))+1], model="text-embedding-ada-002")['data'][0]['embedding']
        # ... set the 'embedding' key in the dictionary to the mean of the embeddings of the two substrings
        entry['embedding'] = np.mean([embedding1, embedding2], axis=0)

    dfList.append(entry)

# Convert dfList to a JSON payload
json_payload = json.dumps(dfList)












# function that generates embeddings from text 
def get_embedding(text, model='text-embedding-ada-002'):
    if isinstance(text, str):
        text = text.replace("\n", " ")
        return openai.Embedding.create(input=[text], model=model)['data'][0]['embedding']
    else:
        return None

df = pd.read_csv('/Users/emilyhalperin/Desktop/halpreads.csv')
conn = sqlite3.connect('instance/app.db')
df.to_sql('halpreads', conn, if_exists='append', index=False)
df['Summary_Embedding'] = df.Summary.replace("\n", " ").apply(get_embedding)


dfList = []
for index, row in df.iterrows():
    #print(index) #To keep track of which row we are on

    # Create an empty dictionary to store the information for this row
    entry = {}
    entry['Title'] = row['Title']
    entry['Author'] = row['Author']
    entry['Genre'] = row['Genre']
    entry['Rating']= row['Rating']
    entry['Summary'] = row['Summary']
    entry['embedding'] = row['Summary_Embedding']

    # If the 'summary' column is a string and its length is greater than or equal to 33000...
    if isinstance(row['Summary'], str) and len(row['Summary']) >= 33000:
        # ... split the 'summary' value at the first period (.) after the middle of the string and take the second half as the first substring
        embedding1 = openai.Embedding.create(
            input = row['Summary'][row['Summary'].find('.', int (len(row['Summary'])/2))+1:], model="text-embedding-ada-002")['data'][0]['embedding']
        # ... take the first half of the 'summary' value as the second substring
        embedding2 = openai.Embedding.create(
            input = row['Summary'][:row['Summary'].find('.', int (len(row['Summary'])/2))+1], model="text-embedding-ada-002")['data'][0]['embedding']
        # ... set the 'embedding' key in the dictionary to the mean of the embeddings of the two substrings
        entry['embedding'] = np.mean([embedding1, embedding2], axis=0)

    dfList.append(entry)

# Convert dfList to a JSON payload
json_payload = json.dumps(dfList)

# Get user query
query = input("Enter your book title: ")

# Convert query to embedding
query_embedding = np.array(openai.Embedding.create(input=query, model="text-embedding-ada-002")['data'][0]['embedding']).flatten()

embedding_dict = {}
for index, row in df.iterrows():
    embedding_dict[row['Title']] = row['Summary_embedding']

print(query_embedding.shape)
distances = distances_from_embeddings(query_embedding, list(embedding_dict.values()), distance_metric="cosine")
indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)

# Print the titles of the top 5 recommended books
print("Titles of top 5 recommended books:")
print(df.loc[indices_of_nearest_neighbors[:5]]['title'])

# Print the genres of the top 5 recommended books
print("\nGenres of top 5 recommended books:")
print(df.loc[indices_of_nearest_neighbors[:5]]['genre'])

# Function that constructs the prompt
def construct_prompt(query, title, author, summary):
    return f"You are a chatbot that recommends books. A user has asked for a recommendation for a book similar to '{query}'. Please recommend a book similar to '{query}' that the user will enjoy. Write a recommendation for the book '{title}' by {author}. Here is a summary of '{title}': {summary}. Be very descriptive about why you chose this book for the user."

# Get the top recommended book
top_recommendation = df.loc[indices_of_nearest_neighbors[0]]

# Construct the prompt
prompt = construct_prompt(query, top_recommendation['title'], top_recommendation['author'], top_recommendation['summarySpaced'])

# Use the OpenAI text completion API to generate a recommendation based on the prompt
completion = openai.Completion.create(model="text-davinci-003", prompt=prompt, max_tokens=1000, temperature=0, stop=None)

# Print the recommendation
print(completion.text)






df = pd.read_csv('/Users/emilyhalperin/Desktop/halpreads.csv')
#conn = sqlite3.connect('instance/app.db')
#df.to_sql('halpreads', conn, if_exists='append', index=False)
df['Summary'] = df.Summary.replace("\n", " ")


dfList = []
for index, row in df.iterrows():
    #print(index) #To keep track of which row we are on

    # Create an empty dictionary to store the information for this row
    entry = {}
    entry['Title'] = row['Title']
    entry['Author'] = row['Author']
    entry['Genre'] = row['Genre']
    entry['Rating']= row['Rating']
    entry['Summary'] = str(row['Summary'])

    # If the length of the 'summary' column is less than 33000...
    if isinstance(row['Summary'], str) and len(row['Summary']) < 33000:
        # ... set the 'embedding' key in the dictionary to the result of calling the 'openai.Embedding.create' function on the 'summary' value
        entry['embedding'] = openai.Embedding.create(
            input = row['Summary'], model="text-embedding-ada-002")['data'][0]['embedding']
        
    # If the length of the 'summary' column is greater than or equal to 33000...
    else:
        # ... split the 'summary' value at the first period (.) after the middle of the string and take the second half as the first substring
        embedding1 = openai.Embedding.create(
            input = row['Summary'][row['Summary'].find('.', int (len(row['Summary'])/2))+1:], model="text-embedding-ada-002")['data'][0]['embedding']
        # ... take the first half of the 'summary' value as the second substring
        embedding2 = openai.Embedding.create(
            input = row['Summary'][:row['Summary'].find('.', int (len(row['Summary'])/2))+1], model="text-embedding-ada-002")['data'][0]['embedding']
        # ... set the 'embedding' key in the dictionary to the mean of the embeddings of the two substrings
        entry['embedding'] = np.mean([embedding1, embedding2], axis=0)
    # Add the dictionary to the list
    dfList.append(entry)
df = pd.DataFrame(dfList)

# Convert dfList to a JSON payload
#json_payload = json.dumps(dfList)

# Get user query
query = input("Enter your book title: ")

# Convert query to embedding
query_embedding = np.array(openai.Embedding.create(input=query, model="text-embedding-ada-002")['data'][0]['embedding'])

embedding_dict =  df.set_index('Title')[['embedding']].to_dict()['embedding']

distances = distances_from_embeddings(query_embedding, list(embedding_dict.values()), distance_metric="cosine")

# Get the indices of the nearest neighbors (i.e., the summaries with the smallest distances)
indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)

# Print the titles of the top 5 recommended books
print("Titles of top 5 recommended books:")
print(df.loc[indices_of_nearest_neighbors[:5]]['title'])

# Print the genres of the top 5 recommended books
print("\nGenres of top 5 recommended books:")
print(df.loc[indices_of_nearest_neighbors[:5]]['genre'])

# Function that constructs the prompt
def construct_prompt(query, title, author, summary):
    return f"You are a chatbot that recommends books. A user has asked for a recommendation for a book similar to '{query}'. Please recommend a book similar to '{query}' that the user will enjoy. Write a recommendation for the book '{title}' by {author}. Here is a summary of '{title}': {summary}. Be very descriptive about why you chose this book for the user."

# Get the top recommended book
top_recommendation = df.loc[indices_of_nearest_neighbors[0]]

# Construct the prompt
prompt = construct_prompt(query, top_recommendation['title'], top_recommendation['author'], top_recommendation['summarySpaced'])

# Use the OpenAI text completion API to generate a recommendation based on the prompt
completion = openai.Completion.create(model="text-davinci-003", prompt=prompt, max_tokens=1000, temperature=0, stop=None)

# Print the recommendation
print(completion.text)